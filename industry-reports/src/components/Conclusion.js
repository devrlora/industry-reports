import React from 'react';
import '../styles/Conclusion.css';

function Conculsion() {
    return (
        <div className="container">
            <div className="ConclusionImage1">
                <img className="imageCon1" src="https://h2q8k3x8.stackpathcdn.com/wp-content/uploads/2017/05/artificial-intelligence-robot-ai.jpg" height="200px"/>
            </div>
            
            <h1>CONCLUSION</h1>

            <p>
                Today’s AI debates are searching for principles to govern emerging and future tech-
                nological systems for the common good. If the “good” involves upholding human
                dignity, then the international human rights system is fit for purpose. If AI researchers,
                developers, and designers work to protect and respect fundamental human rights,
                they could open the path for broad social benefit. To disregard human rights would be
                to close off that path.
            </p>

            <h1>
                IF AI RESEARCHERS, DEVELOPERS, AND
                DESIGNERS WORKED TO PROTECT AND RESPECT
                FUNDAMENTAL HUMAN RIGHTS, IT COULD OPEN
                THE PATH FOR SOCIAL BENEFIT. TO DISREGARD
                HUMAN RIGHTS WOULD BE TO CLOSE OFF THAT PATH.
            </h1>

            <p>
                Of course, human rights have limitations. While international human rights law and
                principles cover a broad class of risks and harms, they are not equipped to address
                all of the known and unknown concerns pertaining to AI. There will be instances
                where AI systems have negative social impacts that are not identifiable or anticipat-
                ed in terms of human rights. While the human rights systems are supported globally
                by deliberative bodies such as the UN and have gained legitimacy through the treaty
                system and national laws, there are still many critics. The very terms “human rights”
                and “human dignity” have long histories replete with intense controversies about their
                intrinsic philosophical and political value.93 And reflecting on our current geopolitical
                moment, the outgoing UN High Commissioner for Human Rights has warned that the
                universal rights system is under attack from chauvinistic nationalism that promotes
                self-interest over the common good
            </p>

            <h3>GOVERNING ARTIFICIAL INTELLIGENCE</h3>

            <p>
                Even if we bring human rights to the center of AI governance discussions, gaps would
                remain between rights, principles, design and development, deployment, and usage.
                Integrating any desirable value into a sociotechnical system is a perennial challenge.95
                In essence, a human rights approach to AI would need to be fully integrated into the
                organizational contexts of technologists, academics, and researchers, as well as in
                the social contexts of users. In doing so, we may also find that AI might influence the
                evolution of human rights and dignity in the future.
                Near-term work in this area should focus on how a human rights approach could be
                practically implemented through policy, practice, and organizational change. Further
                to this goal, this report offers some initial recommendations:
            </p>

                <div className="ConclusionImage2">
                    <img className="imageCon2" src="https://news.blrstage.com/app/uploads/sites/3/2018/11/AI-Machine-Learning-5.jpg" height="200px"/>
                </div>

                <div>
                    <ul>
                        <li>
                        Technology companies should find effective channels of communication with local civil
                        society groups and researchers – particularly in geographic areas where human rights
                        concerns are high – in order to identify and respond to risks related to AI deployments.
                        </li>
                            
                        <li>
                        Technology companies and researchers should conduct HRIAs throughout the life
                        cycle of their AI systems. Researchers should reevaluate HRIA methodology for AI,
                        particularly in light of new developments in algorithmic impact assessments. Toolkits
                        should be developed to assess specific industry needs.
                        </li>
                            
                        <li>
                        Governments should acknowledge their human rights obligations and incorporate a
                        duty to protect fundamental rights in national AI policies, guidelines, and possible regu-
                        lations. Governments can play a more active role in multilateral institutions, like the UN,
                        to advocate for AI development that respects human rights.
                        </li>
                            
                        <li>
                        Since human rights principles were not written as technical specifications, human
                        rights lawyers, policy makers, social scientists, computer scientists, and engineers
                        should work together to operationalize human rights into business models, workflows,
                        and product design.
                        </li>

                        <li>
                        Academics should further examine the value, limitations, and interactions between hu-
                        man rights law and human dignity approaches; humanitarian law; and ethics in relation
                        to emerging AI technologies. Human rights and legal scholars should work with other
                        stakeholders on the tradeoffs between rights when faced with specific AI risks and
                        harms. Social science researchers should empirically investigate the on-the-ground
                        impact of AI on human rights.
                        </li>
                            
                        <li>
                        UN human rights investigators and special rapporteurs should continue researching
                        and publicizing the human rights impacts resulting from AI systems. UN officials and
                        participating governments should evaluate whether existing UN mechanisms for inter-
                        national rights monitoring, accountability, and redress are adequate to respond to AI
                        and other rapidly emerging technologies. UN leadership should also assume a central
                        role in international technology debates by promoting shared global values based on
                        fundamental rights and human dignity.
                        </li>
                    </ul>
                </div>

                <div className="ConclusionImage3">
                    <img className="imageCon3" src="https://news.blrstage.com/app/uploads/sites/3/2018/11/AI-Machine-Learning-5.jpg" height="200px"/>
                </div>
        </div>

    );

}
export default Conclusion;